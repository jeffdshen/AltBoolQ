{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwnF_yXSNwe"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4NT5HSASRUZ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZRcUfPmuDV3"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH_TO_DATASETS = \"datasets\"\n",
        "WANDB_ENTITY = \"_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-eW1vDnK4rF"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "from altboolq import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f5JvBzsK-Px"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'max_len': None,\n",
        "    'lr': 4e-4,\n",
        "    'betas': (0.9, 0.98),\n",
        "    'eps': 1e-6,\n",
        "    'wd': 0.1,\n",
        "    'num_epochs': 5,\n",
        "    'eval_per_n_samples' : 4000,\n",
        "    'mini_val': 1024,\n",
        "    'stride': 0,\n",
        "    'warmup_steps': 400,\n",
        "    'gradient_accumulation' : 4,\n",
        "    'max_grad_norm' : None,\n",
        "    'train_loss_ema' : 0.999,\n",
        "    'model_path': 'roberta-large',\n",
        "    'train_df': 'allboolq_train_v5',\n",
        "    'valid_df': 'allboolq_valid_v5_half',\n",
        "    'dropout': None,\n",
        "    'batch_size': 4,\n",
        "    'model_batch_size': 4,\n",
        "    'seed': 42,\n",
        "    'head': 'cls',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "d018ee9ee8f744769e62732178ef4a77",
            "4e6d68e42d214a12bca2c474c6b06b97",
            "741705ca36c34d7aabb7ce438dca1f4f",
            "fc27ca98d0914522a05ec9a91ed2203d",
            "eff36053cbf4492eaf84f7838c4b5c7f",
            "532f021641ee4b01984ed9051344735d",
            "34fcf84bab344dcea55f5db2b8f4dcbf",
            "0351009751ab491e83e6e896cbb78b52",
            "6a433da7572548d8bfcf1d79f5c3d285",
            "f9ecc3760ebf46299a989d0c15c1feb9",
            "d1f1cbdbbfa342409bd5b818d84b6806"
          ]
        },
        "id": "ygWXRKm9K-eM",
        "outputId": "4f2d37ee-b849-4a4c-fae3-fdcaa1c30b18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset super_glue (/root/.cache/huggingface/datasets/super_glue/boolq/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d018ee9ee8f744769e62732178ef4a77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "dict_keys(['boolq_train', 'boolq_valid', 'boolq_test', 'open_boolq_train', 'open_boolq_valid', 'open_boolq_test', 'maskboolq_train_v1', 'maskboolq_valid_v1', 'maskboolq_test_v1', 'maskboolq_train_v2', 'maskboolq_valid_v2', 'maskboolq_test_v2', 'maskboolq_train_v3', 'maskboolq_valid_v3', 'maskboolq_test_v3', 'maskboolq_train_v4', 'maskboolq_valid_v4', 'maskboolq_test_v4', 'maskboolq_train_v5', 'maskboolq_valid_v5', 'maskboolq_test_v5', 'altboolq_train_v5', 'altboolq_valid_v5', 'allboolq_valid_v5', 'allboolq_train_v5', 'altboolq_valid_v4', 'altboolq_train_v4', 'allboolq_valid_v5_half'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs = get_dfs(PATH_TO_DATASETS)\n",
        "dfs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjvWxzusRHut"
      },
      "source": [
        "## Roberta-Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "UbEqZZ85PC8E",
        "outputId": "4d1732dd-c02f-4c85-bc22-36353712d731"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWD8_BdpLExK",
        "outputId": "c09ab30c-c987-4995-c6a2-d3ae10b9cf07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: {\n",
            "    \"batch_size\": 4,\n",
            "    \"betas\": [\n",
            "        0.9,\n",
            "        0.98\n",
            "    ],\n",
            "    \"dropout\": null,\n",
            "    \"eps\": 1e-06,\n",
            "    \"eval_per_n_samples\": 4000,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"head\": \"cls\",\n",
            "    \"lr\": 0.0004,\n",
            "    \"max_grad_norm\": null,\n",
            "    \"max_len\": null,\n",
            "    \"mini_val\": 1024,\n",
            "    \"model_batch_size\": 4,\n",
            "    \"model_path\": \"roberta-large\",\n",
            "    \"num_epochs\": 5,\n",
            "    \"seed\": 42,\n",
            "    \"stride\": 0,\n",
            "    \"train_df\": \"allboolq_train_v5\",\n",
            "    \"train_loss_ema\": 0.999,\n",
            "    \"valid_df\": \"allboolq_valid_v5_half\",\n",
            "    \"warmup_steps\": 400,\n",
            "    \"wd\": 0.1\n",
            "}\n",
            "Loading model: roberta-large\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Starting epoch 0\n",
            "epoch:  0 | sample:   4000 | lr: 1.26e-05 | train_loss:  0.6489 | valid_loss:  0.5770 | train_error:  0.6770 | valid_error:  0.7175 (Best)\n",
            "epoch:  0 | sample:   8000 | lr: 1.78e-05 | train_loss:  0.4677 | valid_loss:  0.4464 | train_error:  0.7605 | valid_error:  0.8005 (Best)\n",
            "epoch:  0 | sample:  12000 | lr: 1.46e-05 | train_loss:  0.4012 | valid_loss:  0.4224 | train_error:  0.8211 | valid_error:  0.8121 (Best)\n",
            "epoch:  0 | sample:  16000 | lr: 1.26e-05 | train_loss:  0.3223 | valid_loss:  0.4005 | train_error:  0.8636 | valid_error:  0.8371 (Best)\n",
            "Starting epoch 1\n",
            "epoch:  1 | sample:  20003 | lr: 1.13e-05 | train_loss:  0.1856 | valid_loss:  0.4386 | train_error:  0.9175 | valid_error:  0.8367\n",
            "epoch:  1 | sample:  24003 | lr: 1.03e-05 | train_loss:  0.1613 | valid_loss:  0.4278 | train_error:  0.9434 | valid_error:  0.8409 (Best)\n",
            "epoch:  1 | sample:  28003 | lr: 9.53e-06 | train_loss:  0.1345 | valid_loss:  0.4855 | train_error:  0.9430 | valid_error:  0.8371\n",
            "epoch:  1 | sample:  32003 | lr: 8.92e-06 | train_loss:  0.1373 | valid_loss:  0.4502 | train_error:  0.9503 | valid_error:  0.8406\n",
            "Starting epoch 2\n",
            "epoch:  2 | sample:  36006 | lr: 8.41e-06 | train_loss:  0.0940 | valid_loss:  0.5672 | train_error:  0.9504 | valid_error:  0.8413 (Best)\n",
            "epoch:  2 | sample:  40006 | lr: 7.98e-06 | train_loss:  0.0434 | valid_loss:  0.6524 | train_error:  0.9879 | valid_error:  0.8494 (Best)\n",
            "epoch:  2 | sample:  44006 | lr: 7.61e-06 | train_loss:  0.0384 | valid_loss:  0.6905 | train_error:  0.9891 | valid_error:  0.8406\n",
            "epoch:  2 | sample:  48006 | lr: 7.28e-06 | train_loss:  0.0456 | valid_loss:  0.6891 | train_error:  0.9904 | valid_error:  0.8403\n",
            "epoch:  2 | sample:  52006 | lr: 6.99e-06 | train_loss:  0.0494 | valid_loss:  0.5921 | train_error:  0.9862 | valid_error:  0.8374\n",
            "Starting epoch 3\n",
            "epoch:  3 | sample:  56009 | lr: 6.74e-06 | train_loss:  0.0223 | valid_loss:  0.7543 | train_error:  0.9969 | valid_error:  0.8371\n",
            "epoch:  3 | sample:  60009 | lr: 6.51e-06 | train_loss:  0.0165 | valid_loss:  0.7507 | train_error:  0.9951 | valid_error:  0.8455\n",
            "epoch:  3 | sample:  64009 | lr: 6.30e-06 | train_loss:  0.0242 | valid_loss:  0.6973 | train_error:  0.9958 | valid_error:  0.8409\n",
            "epoch:  3 | sample:  68009 | lr: 6.12e-06 | train_loss:  0.0177 | valid_loss:  0.7717 | train_error:  0.9946 | valid_error:  0.8406\n",
            "Starting epoch 4\n",
            "epoch:  4 | sample:  72012 | lr: 5.94e-06 | train_loss:  0.0049 | valid_loss:  0.9839 | train_error:  0.9972 | valid_error:  0.8474\n",
            "epoch:  4 | sample:  76012 | lr: 5.79e-06 | train_loss:  0.0056 | valid_loss:  0.9740 | train_error:  0.9977 | valid_error:  0.8445\n",
            "epoch:  4 | sample:  80012 | lr: 5.64e-06 | train_loss:  0.0152 | valid_loss:  0.7697 | train_error:  0.9943 | valid_error:  0.8445\n",
            "epoch:  4 | sample:  84012 | lr: 5.50e-06 | train_loss:  0.0082 | valid_loss:  0.9446 | train_error:  0.9963 | valid_error:  0.8377\n",
            "Best: 0.8493683187560739\n"
          ]
        }
      ],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "d23a90289e9a4e319c4528430f539752",
            "0d750302d988447cb11ded4da36ed541",
            "1277a2af1b314054bb77587439c6ed0e",
            "b9eb488922d641188a63eba6ad60f529",
            "34485ae589f34d898fd1535eb2a59dda",
            "f2a862e21b2c4defb6f638c4bd462768",
            "203c92d14bff4afda086771588bfe3cb",
            "9bcfca6c08ff48b9a7e5ca1e627ce34d"
          ]
        },
        "id": "BxPM0H75LI7n",
        "outputId": "e24b751f-8e66-4186-eaf7-f1edc26cf723"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76DtP-ZgQ2-u"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 2e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "VRlwfkR6Syg6",
        "outputId": "bded4b25-f82d-4a7a-98d9-42c001b95ead"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOIYiFv8QzLK",
        "outputId": "ae13baf8-4ce7-4e0e-e1c8-9a692615bd43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: {\n",
            "    \"batch_size\": 4,\n",
            "    \"betas\": [\n",
            "        0.9,\n",
            "        0.98\n",
            "    ],\n",
            "    \"dropout\": null,\n",
            "    \"eps\": 1e-06,\n",
            "    \"eval_per_n_samples\": 4000,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"head\": \"cls\",\n",
            "    \"lr\": 0.0002,\n",
            "    \"max_grad_norm\": null,\n",
            "    \"max_len\": null,\n",
            "    \"mini_val\": 1024,\n",
            "    \"model_batch_size\": 4,\n",
            "    \"model_path\": \"roberta-large\",\n",
            "    \"num_epochs\": 5,\n",
            "    \"seed\": 42,\n",
            "    \"stride\": 0,\n",
            "    \"train_df\": \"allboolq_train_v5\",\n",
            "    \"train_loss_ema\": 0.999,\n",
            "    \"valid_df\": \"allboolq_valid_v5_half\",\n",
            "    \"warmup_steps\": 400,\n",
            "    \"wd\": 0.1\n",
            "}\n",
            "Loading model: roberta-large\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Starting epoch 0\n",
            "epoch:  0 | sample:   4000 | lr: 6.28e-06 | train_loss:  0.6604 | valid_loss:  0.6557 | train_error:  0.6767 | valid_error:  0.6281 (Best)\n",
            "epoch:  0 | sample:   8000 | lr: 8.92e-06 | train_loss:  0.5143 | valid_loss:  0.4463 | train_error:  0.7098 | valid_error:  0.7979 (Best)\n",
            "epoch:  0 | sample:  12000 | lr: 7.28e-06 | train_loss:  0.4069 | valid_loss:  0.3958 | train_error:  0.8220 | valid_error:  0.8241 (Best)\n",
            "epoch:  0 | sample:  16000 | lr: 6.30e-06 | train_loss:  0.3253 | valid_loss:  0.3694 | train_error:  0.8594 | valid_error:  0.8380 (Best)\n",
            "Starting epoch 1\n",
            "epoch:  1 | sample:  20003 | lr: 5.64e-06 | train_loss:  0.2026 | valid_loss:  0.4140 | train_error:  0.9024 | valid_error:  0.8322\n",
            "epoch:  1 | sample:  24003 | lr: 5.15e-06 | train_loss:  0.1873 | valid_loss:  0.3995 | train_error:  0.9371 | valid_error:  0.8490 (Best)\n",
            "epoch:  1 | sample:  28003 | lr: 4.77e-06 | train_loss:  0.1642 | valid_loss:  0.4165 | train_error:  0.9402 | valid_error:  0.8419\n",
            "epoch:  1 | sample:  32003 | lr: 4.46e-06 | train_loss:  0.1713 | valid_loss:  0.3941 | train_error:  0.9394 | valid_error:  0.8477\n",
            "Starting epoch 2\n",
            "epoch:  2 | sample:  36006 | lr: 4.20e-06 | train_loss:  0.1206 | valid_loss:  0.4714 | train_error:  0.9310 | valid_error:  0.8406\n",
            "epoch:  2 | sample:  40006 | lr: 3.99e-06 | train_loss:  0.0576 | valid_loss:  0.4965 | train_error:  0.9855 | valid_error:  0.8403\n",
            "epoch:  2 | sample:  44006 | lr: 3.80e-06 | train_loss:  0.0444 | valid_loss:  0.5797 | train_error:  0.9894 | valid_error:  0.8442\n",
            "epoch:  2 | sample:  48006 | lr: 3.64e-06 | train_loss:  0.0390 | valid_loss:  0.6621 | train_error:  0.9851 | valid_error:  0.8461\n",
            "epoch:  2 | sample:  52006 | lr: 3.50e-06 | train_loss:  0.0479 | valid_loss:  0.5698 | train_error:  0.9851 | valid_error:  0.8481\n",
            "Starting epoch 3\n",
            "epoch:  3 | sample:  56009 | lr: 3.37e-06 | train_loss:  0.0173 | valid_loss:  0.7590 | train_error:  0.9947 | valid_error:  0.8341\n",
            "epoch:  3 | sample:  60009 | lr: 3.26e-06 | train_loss:  0.0144 | valid_loss:  0.7425 | train_error:  0.9950 | valid_error:  0.8455\n",
            "epoch:  3 | sample:  64009 | lr: 3.15e-06 | train_loss:  0.0098 | valid_loss:  0.8318 | train_error:  0.9949 | valid_error:  0.8448\n",
            "epoch:  3 | sample:  68009 | lr: 3.06e-06 | train_loss:  0.0129 | valid_loss:  0.7776 | train_error:  0.9962 | valid_error:  0.8403\n",
            "Starting epoch 4\n",
            "epoch:  4 | sample:  72012 | lr: 2.97e-06 | train_loss:  0.0099 | valid_loss:  0.8230 | train_error:  0.9970 | valid_error:  0.8390\n",
            "epoch:  4 | sample:  76012 | lr: 2.89e-06 | train_loss:  0.0073 | valid_loss:  0.8607 | train_error:  0.9987 | valid_error:  0.8400\n",
            "epoch:  4 | sample:  80012 | lr: 2.82e-06 | train_loss:  0.0111 | valid_loss:  0.8535 | train_error:  0.9967 | valid_error:  0.8419\n",
            "epoch:  4 | sample:  84012 | lr: 2.75e-06 | train_loss:  0.0077 | valid_loss:  1.0260 | train_error:  0.9964 | valid_error:  0.8338\n",
            "Best: 0.8490443796566246\n"
          ]
        }
      ],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "78524a702c13478c87a19ad63dbeb419",
            "f913019f7f604034a3f16e76d3206290",
            "39c19ccd20a54452afa6bef88184a198",
            "bf9e4659b41e41be85de337a5fd4b64c",
            "b6c48168bea24dc5b73ab4c8eaa401ab",
            "bdf9ef56e35540488fc3b1ff176bd42b",
            "e4f843dc2dd744a1937cdc2c6206ffab",
            "33ccbc021a564c20847379fc4b5bfbfe"
          ]
        },
        "id": "ccvxfPb_Q1Jd",
        "outputId": "02b6f048-cb63-4305-f92e-6501bb6cb12c"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efqvwroqRKVz"
      },
      "source": [
        "## Roberta-Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9I7M9y_RLur"
      },
      "outputs": [],
      "source": [
        "config.update({\"model_path\": \"roberta-base\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxv2Ek8GREeM"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 4e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "XnODQ4lhRFKo",
        "outputId": "a24d1d2a-4c8f-494e-b3a9-00f9b3303dd0"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciaefAqtRFsP",
        "outputId": "75918eac-dcfb-42ef-a881-cd0d8f86fa25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: {\n",
            "    \"batch_size\": 4,\n",
            "    \"betas\": [\n",
            "        0.9,\n",
            "        0.98\n",
            "    ],\n",
            "    \"dropout\": null,\n",
            "    \"eps\": 1e-06,\n",
            "    \"eval_per_n_samples\": 4000,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"head\": \"cls\",\n",
            "    \"lr\": 0.0004,\n",
            "    \"max_grad_norm\": null,\n",
            "    \"max_len\": null,\n",
            "    \"mini_val\": 1024,\n",
            "    \"model_batch_size\": 4,\n",
            "    \"model_path\": \"roberta-base\",\n",
            "    \"num_epochs\": 5,\n",
            "    \"seed\": 42,\n",
            "    \"stride\": 0,\n",
            "    \"train_df\": \"allboolq_train_v5\",\n",
            "    \"train_loss_ema\": 0.999,\n",
            "    \"valid_df\": \"allboolq_valid_v5_half\",\n",
            "    \"warmup_steps\": 400,\n",
            "    \"wd\": 0.1\n",
            "}\n",
            "Loading model: roberta-base\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Starting epoch 0\n",
            "epoch:  0 | sample:   4000 | lr: 1.27e-05 | train_loss:  0.6609 | valid_loss:  0.6512 | train_error:  0.6682 | valid_error:  0.6281 (Best)\n",
            "epoch:  0 | sample:   8000 | lr: 1.78e-05 | train_loss:  0.5865 | valid_loss:  0.5597 | train_error:  0.6684 | valid_error:  0.7175 (Best)\n",
            "epoch:  0 | sample:  12000 | lr: 1.45e-05 | train_loss:  0.4794 | valid_loss:  0.5108 | train_error:  0.7550 | valid_error:  0.7561 (Best)\n",
            "epoch:  0 | sample:  16000 | lr: 1.26e-05 | train_loss:  0.4146 | valid_loss:  0.4829 | train_error:  0.7817 | valid_error:  0.7778 (Best)\n",
            "Starting epoch 1\n",
            "epoch:  1 | sample:  20003 | lr: 1.13e-05 | train_loss:  0.2933 | valid_loss:  0.5150 | train_error:  0.8766 | valid_error:  0.7762\n",
            "epoch:  1 | sample:  24003 | lr: 1.03e-05 | train_loss:  0.2777 | valid_loss:  0.5249 | train_error:  0.8841 | valid_error:  0.7762\n",
            "epoch:  1 | sample:  28003 | lr: 9.53e-06 | train_loss:  0.2462 | valid_loss:  0.5069 | train_error:  0.8987 | valid_error:  0.7868 (Best)\n",
            "epoch:  1 | sample:  32003 | lr: 8.92e-06 | train_loss:  0.2252 | valid_loss:  0.5525 | train_error:  0.9074 | valid_error:  0.7817\n",
            "Starting epoch 2\n",
            "epoch:  2 | sample:  36006 | lr: 8.41e-06 | train_loss:  0.1507 | valid_loss:  0.6282 | train_error:  0.9196 | valid_error:  0.7817\n",
            "epoch:  2 | sample:  40006 | lr: 7.97e-06 | train_loss:  0.0875 | valid_loss:  0.6632 | train_error:  0.9780 | valid_error:  0.7885 (Best)\n",
            "epoch:  2 | sample:  44006 | lr: 7.60e-06 | train_loss:  0.0825 | valid_loss:  0.7119 | train_error:  0.9764 | valid_error:  0.7635\n",
            "epoch:  2 | sample:  48006 | lr: 7.28e-06 | train_loss:  0.0819 | valid_loss:  0.6987 | train_error:  0.9784 | valid_error:  0.7703\n",
            "epoch:  2 | sample:  52006 | lr: 6.99e-06 | train_loss:  0.0829 | valid_loss:  0.6737 | train_error:  0.9821 | valid_error:  0.7826\n",
            "Starting epoch 3\n",
            "epoch:  3 | sample:  56009 | lr: 6.74e-06 | train_loss:  0.0334 | valid_loss:  0.9204 | train_error:  0.9917 | valid_error:  0.7820\n",
            "epoch:  3 | sample:  60009 | lr: 6.51e-06 | train_loss:  0.0255 | valid_loss:  1.0300 | train_error:  0.9925 | valid_error:  0.7752\n",
            "epoch:  3 | sample:  64009 | lr: 6.30e-06 | train_loss:  0.0357 | valid_loss:  0.8639 | train_error:  0.9898 | valid_error:  0.7846\n",
            "epoch:  3 | sample:  68009 | lr: 6.12e-06 | train_loss:  0.0312 | valid_loss:  0.9578 | train_error:  0.9895 | valid_error:  0.7762\n",
            "Starting epoch 4\n",
            "epoch:  4 | sample:  72012 | lr: 5.94e-06 | train_loss:  0.0113 | valid_loss:  1.2798 | train_error:  0.9979 | valid_error:  0.7648\n",
            "epoch:  4 | sample:  76012 | lr: 5.78e-06 | train_loss:  0.0095 | valid_loss:  1.2334 | train_error:  0.9958 | valid_error:  0.7807\n",
            "epoch:  4 | sample:  80012 | lr: 5.64e-06 | train_loss:  0.0153 | valid_loss:  1.0803 | train_error:  0.9937 | valid_error:  0.7852\n",
            "epoch:  4 | sample:  84012 | lr: 5.50e-06 | train_loss:  0.0206 | valid_loss:  1.2001 | train_error:  0.9988 | valid_error:  0.7813\n",
            "Best: 0.7884677680596048\n"
          ]
        }
      ],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355,
          "referenced_widgets": [
            "450545f2db7e4433abcdd677c1f03a22",
            "108228e49d0943f19e6e0d7c7832d152",
            "1617a802d24f4cf2b9780c0b5f5cd358",
            "e830c57b342f4790a779f1b4a80aa35d",
            "e6947c5baf8d4d2d80b5f590ecc93495",
            "cdd3bd833d3449e8974de60ab263f34c",
            "e7e7a7f97a384dc5852184cc7be06db6",
            "7083c50ac0ad40b897231c689f649583"
          ]
        },
        "id": "TSNTFAUeRGPJ",
        "outputId": "d2117fb7-752f-49d8-9456-a3721f1ef4f0"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HFv-oVeCRfpD"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 2e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YKnFTl_YRhzq"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ziAYCbrDRkBX"
      },
      "outputs": [],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E1Qmf9zNRlLm"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1lhZIURrjY"
      },
      "source": [
        "## Bert-Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUYDwIV1RrjY"
      },
      "outputs": [],
      "source": [
        "config.update({\"model_path\": \"bert-large-cased\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSBIR1NuRrjZ"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 4e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "C8s_TtEsRrjZ",
        "outputId": "28d683d2-c1bd-4243-8fd3-2d9fb212ff8f"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmsexzk8RrjZ",
        "outputId": "0a3c40e7-333d-4ee6-888e-a991b0c418c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: {\n",
            "    \"batch_size\": 4,\n",
            "    \"betas\": [\n",
            "        0.9,\n",
            "        0.98\n",
            "    ],\n",
            "    \"dropout\": null,\n",
            "    \"eps\": 1e-06,\n",
            "    \"eval_per_n_samples\": 4000,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"head\": \"cls\",\n",
            "    \"lr\": 0.0004,\n",
            "    \"max_grad_norm\": null,\n",
            "    \"max_len\": null,\n",
            "    \"mini_val\": 1024,\n",
            "    \"model_batch_size\": 4,\n",
            "    \"model_path\": \"bert-large-cased\",\n",
            "    \"num_epochs\": 5,\n",
            "    \"seed\": 42,\n",
            "    \"stride\": 0,\n",
            "    \"train_df\": \"allboolq_train_v5\",\n",
            "    \"train_loss_ema\": 0.999,\n",
            "    \"valid_df\": \"allboolq_valid_v5_half\",\n",
            "    \"warmup_steps\": 400,\n",
            "    \"wd\": 0.1\n",
            "}\n",
            "Loading model: bert-large-cased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Starting epoch 0\n",
            "epoch:  0 | sample:   4000 | lr: 1.27e-05 | train_loss:  0.6481 | valid_loss:  0.6281 | train_error:  0.6728 | valid_error:  0.6638 (Best)\n",
            "epoch:  0 | sample:   8000 | lr: 1.78e-05 | train_loss:  0.5635 | valid_loss:  0.5592 | train_error:  0.6742 | valid_error:  0.7075 (Best)\n",
            "epoch:  0 | sample:  12000 | lr: 1.45e-05 | train_loss:  0.5019 | valid_loss:  0.5410 | train_error:  0.7410 | valid_error:  0.7347 (Best)\n",
            "epoch:  0 | sample:  16000 | lr: 1.26e-05 | train_loss:  0.4402 | valid_loss:  0.5169 | train_error:  0.7814 | valid_error:  0.7587 (Best)\n",
            "Starting epoch 1\n",
            "epoch:  1 | sample:  20003 | lr: 1.13e-05 | train_loss:  0.2288 | valid_loss:  0.6246 | train_error:  0.8932 | valid_error:  0.7344\n",
            "epoch:  1 | sample:  24003 | lr: 1.03e-05 | train_loss:  0.2030 | valid_loss:  0.5917 | train_error:  0.9119 | valid_error:  0.7648 (Best)\n",
            "epoch:  1 | sample:  28003 | lr: 9.53e-06 | train_loss:  0.1757 | valid_loss:  0.5887 | train_error:  0.9350 | valid_error:  0.7745 (Best)\n",
            "epoch:  1 | sample:  32003 | lr: 8.92e-06 | train_loss:  0.1614 | valid_loss:  0.7098 | train_error:  0.9241 | valid_error:  0.7570\n",
            "Starting epoch 2\n",
            "epoch:  2 | sample:  36006 | lr: 8.41e-06 | train_loss:  0.0838 | valid_loss:  0.7098 | train_error:  0.9485 | valid_error:  0.7791 (Best)\n",
            "epoch:  2 | sample:  40006 | lr: 7.97e-06 | train_loss:  0.0422 | valid_loss:  0.8400 | train_error:  0.9877 | valid_error:  0.7758\n",
            "epoch:  2 | sample:  44006 | lr: 7.60e-06 | train_loss:  0.0452 | valid_loss:  0.8652 | train_error:  0.9875 | valid_error:  0.7768\n",
            "epoch:  2 | sample:  48006 | lr: 7.28e-06 | train_loss:  0.0357 | valid_loss:  0.8627 | train_error:  0.9864 | valid_error:  0.7768\n",
            "epoch:  2 | sample:  52006 | lr: 6.99e-06 | train_loss:  0.0456 | valid_loss:  0.7863 | train_error:  0.9853 | valid_error:  0.7758\n",
            "Starting epoch 3\n",
            "epoch:  3 | sample:  56009 | lr: 6.74e-06 | train_loss:  0.0118 | valid_loss:  1.0588 | train_error:  0.9956 | valid_error:  0.7752\n",
            "epoch:  3 | sample:  60009 | lr: 6.51e-06 | train_loss:  0.0124 | valid_loss:  1.0983 | train_error:  0.9947 | valid_error:  0.7775\n",
            "epoch:  3 | sample:  64009 | lr: 6.31e-06 | train_loss:  0.0080 | valid_loss:  1.1447 | train_error:  0.9965 | valid_error:  0.7823 (Best)\n",
            "epoch:  3 | sample:  68009 | lr: 6.12e-06 | train_loss:  0.0187 | valid_loss:  1.0301 | train_error:  0.9953 | valid_error:  0.7745\n",
            "Starting epoch 4\n",
            "epoch:  4 | sample:  72012 | lr: 5.95e-06 | train_loss:  0.0079 | valid_loss:  1.1282 | train_error:  0.9966 | valid_error:  0.7784\n",
            "epoch:  4 | sample:  76012 | lr: 5.79e-06 | train_loss:  0.0107 | valid_loss:  1.3372 | train_error:  0.9976 | valid_error:  0.7787\n",
            "epoch:  4 | sample:  80012 | lr: 5.64e-06 | train_loss:  0.0096 | valid_loss:  1.3671 | train_error:  0.9991 | valid_error:  0.7768\n",
            "epoch:  4 | sample:  84012 | lr: 5.50e-06 | train_loss:  0.0062 | valid_loss:  1.3748 | train_error:  0.9964 | valid_error:  0.7843 (Best)\n",
            "Best: 0.7842565597667639\n"
          ]
        }
      ],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 52,
          "referenced_widgets": [
            "93c7c6c1b90246caa160ea42c2581849"
          ]
        },
        "id": "5bpyN3gKRrjZ",
        "outputId": "0a710a8d-23cd-4047-a91c-835dbd98bdaf"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IKiXtDvIRrjZ"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 2e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xoFYJHinRrja"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "twT2xLCbRrja"
      },
      "outputs": [],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rO1bQIdXRrja"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzj7nRJnR0jN"
      },
      "source": [
        "## Bert-Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0hhnPu60R0jV"
      },
      "outputs": [],
      "source": [
        "config.update({\"model_path\": \"bert-base-cased\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lYuLdBj2R0jV"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 4e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5we1HwtOR0jV",
        "outputId": "f56d5f83-2907-4302-a502-10097f7a7318"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgr8otKdR0jV",
        "outputId": "e697b3cb-8eff-4e1f-c821-bea96588891b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config: {\n",
            "    \"batch_size\": 4,\n",
            "    \"betas\": [\n",
            "        0.9,\n",
            "        0.98\n",
            "    ],\n",
            "    \"dropout\": null,\n",
            "    \"eps\": 1e-06,\n",
            "    \"eval_per_n_samples\": 4000,\n",
            "    \"gradient_accumulation\": 4,\n",
            "    \"head\": \"cls\",\n",
            "    \"lr\": 0.0004,\n",
            "    \"max_grad_norm\": null,\n",
            "    \"max_len\": null,\n",
            "    \"mini_val\": 1024,\n",
            "    \"model_batch_size\": 4,\n",
            "    \"model_path\": \"bert-base-cased\",\n",
            "    \"num_epochs\": 5,\n",
            "    \"seed\": 42,\n",
            "    \"stride\": 0,\n",
            "    \"train_df\": \"allboolq_train_v5\",\n",
            "    \"train_loss_ema\": 0.999,\n",
            "    \"valid_df\": \"allboolq_valid_v5_half\",\n",
            "    \"warmup_steps\": 400,\n",
            "    \"wd\": 0.1\n",
            "}\n",
            "Loading model: bert-base-cased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Starting epoch 0\n",
            "epoch:  0 | sample:   4000 | lr: 1.26e-05 | train_loss:  0.6535 | valid_loss:  0.6373 | train_error:  0.6792 | valid_error:  0.6320 (Best)\n",
            "epoch:  0 | sample:   8000 | lr: 1.78e-05 | train_loss:  0.5923 | valid_loss:  0.5956 | train_error:  0.6703 | valid_error:  0.6868 (Best)\n",
            "epoch:  0 | sample:  12000 | lr: 1.46e-05 | train_loss:  0.5333 | valid_loss:  0.5573 | train_error:  0.7337 | valid_error:  0.7123 (Best)\n",
            "epoch:  0 | sample:  16000 | lr: 1.26e-05 | train_loss:  0.4549 | valid_loss:  0.5458 | train_error:  0.7698 | valid_error:  0.7366 (Best)\n",
            "Starting epoch 1\n",
            "epoch:  1 | sample:  20003 | lr: 1.13e-05 | train_loss:  0.2951 | valid_loss:  0.5936 | train_error:  0.8703 | valid_error:  0.7366\n",
            "epoch:  1 | sample:  24003 | lr: 1.03e-05 | train_loss:  0.2317 | valid_loss:  0.7024 | train_error:  0.9124 | valid_error:  0.7373 (Best)\n",
            "epoch:  1 | sample:  28003 | lr: 9.53e-06 | train_loss:  0.2164 | valid_loss:  0.6451 | train_error:  0.9134 | valid_error:  0.7324\n",
            "epoch:  1 | sample:  32003 | lr: 8.92e-06 | train_loss:  0.1790 | valid_loss:  0.6844 | train_error:  0.9233 | valid_error:  0.7438 (Best)\n",
            "Starting epoch 2\n",
            "epoch:  2 | sample:  36006 | lr: 8.41e-06 | train_loss:  0.1030 | valid_loss:  0.7524 | train_error:  0.9338 | valid_error:  0.7480 (Best)\n",
            "epoch:  2 | sample:  40006 | lr: 7.97e-06 | train_loss:  0.0439 | valid_loss:  0.9362 | train_error:  0.9844 | valid_error:  0.7460\n",
            "epoch:  2 | sample:  44006 | lr: 7.60e-06 | train_loss:  0.0378 | valid_loss:  0.9674 | train_error:  0.9820 | valid_error:  0.7418\n",
            "epoch:  2 | sample:  48006 | lr: 7.28e-06 | train_loss:  0.0409 | valid_loss:  0.9840 | train_error:  0.9865 | valid_error:  0.7444\n",
            "epoch:  2 | sample:  52006 | lr: 6.99e-06 | train_loss:  0.0418 | valid_loss:  1.0077 | train_error:  0.9860 | valid_error:  0.7486 (Best)\n",
            "Starting epoch 3\n",
            "epoch:  3 | sample:  56009 | lr: 6.74e-06 | train_loss:  0.0278 | valid_loss:  1.0624 | train_error:  0.9938 | valid_error:  0.7522 (Best)\n",
            "epoch:  3 | sample:  60009 | lr: 6.51e-06 | train_loss:  0.0100 | valid_loss:  1.1746 | train_error:  0.9951 | valid_error:  0.7509\n",
            "epoch:  3 | sample:  64009 | lr: 6.31e-06 | train_loss:  0.0143 | valid_loss:  1.2568 | train_error:  0.9953 | valid_error:  0.7512\n",
            "epoch:  3 | sample:  68009 | lr: 6.12e-06 | train_loss:  0.0210 | valid_loss:  1.1983 | train_error:  0.9948 | valid_error:  0.7425\n",
            "Starting epoch 4\n",
            "epoch:  4 | sample:  72012 | lr: 5.95e-06 | train_loss:  0.0061 | valid_loss:  1.2884 | train_error:  0.9962 | valid_error:  0.7460\n",
            "epoch:  4 | sample:  76012 | lr: 5.79e-06 | train_loss:  0.0103 | valid_loss:  1.4041 | train_error:  0.9995 | valid_error:  0.7493\n",
            "epoch:  4 | sample:  80012 | lr: 5.64e-06 | train_loss:  0.0059 | valid_loss:  1.3233 | train_error:  0.9973 | valid_error:  0.7554 (Best)\n",
            "epoch:  4 | sample:  84012 | lr: 5.50e-06 | train_loss:  0.0206 | valid_loss:  1.2559 | train_error:  0.9940 | valid_error:  0.7509\n",
            "Best: 0.7554259799157759\n"
          ]
        }
      ],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3zIXlwSaR0jV"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RZTxX5DZR0jV"
      },
      "outputs": [],
      "source": [
        "config.update({\"lr\": 2e-4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C1Jn_8XIR0jV"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"AltBoolQ\", entity=WANDB_ENTITY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "88NkkukOR0jV"
      },
      "outputs": [],
      "source": [
        "run(dfs, config, wandb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KiArX2s1R0jW"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylr0KUJU0Bvk"
      },
      "source": [
        "# Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nve1L7Zq12ya"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtOntIOS49O9"
      },
      "outputs": [],
      "source": [
        "filters = {\n",
        "    \"$or\": [{\"config.valid_df\": \"boolq_valid\"},\n",
        "            {\"config.valid_df\": \"altboolq_valid_v5\"},\n",
        "            {\"config.valid_df\": \"allboolq_valid_v5_half\"},\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2TCONKd0Bvk"
      },
      "outputs": [],
      "source": [
        "models = download_models(wandb, project=\"AltBoolQ\", name=\"best.pth\", filters=filters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncJrF9xHyz9i"
      },
      "outputs": [],
      "source": [
        "df_names = [\"boolq_valid\", \"altboolq_valid_v5\"]\n",
        "values = [\n",
        "    (\"roberta-large\", \"boolq_valid\", 0.0002),\n",
        "    (\"roberta-large\", \"altboolq_valid_v5\", 0.0002),\n",
        "    (\"roberta-large\", \"allboolq_valid_v5_half\", 0.0004),\n",
        "    (\"roberta-base\", \"boolq_valid\", 0.0004),\n",
        "    (\"roberta-base\", \"altboolq_valid_v5\", 0.0004),\n",
        "    (\"roberta-base\", \"allboolq_valid_v5_half\", 0.0004),\n",
        "    (\"bert-large-cased\", \"boolq_valid\", 0.0004),\n",
        "    (\"bert-large-cased\", \"altboolq_valid_v5\", 0.0004),\n",
        "    (\"bert-large-cased\", \"allboolq_valid_v5_half\", 0.0004),\n",
        "    (\"bert-base-cased\", \"boolq_valid\", 0.0004),\n",
        "    (\"bert-base-cased\", \"altboolq_valid_v5\", 0.0004),\n",
        "    (\"bert-base-cased\", \"allboolq_valid_v5_half\", 0.0004),\n",
        "]\n",
        "values_format = \"{0}-{1}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4r53R_YX8XK6"
      },
      "outputs": [],
      "source": [
        "value_names = (\"model\", \"valid_df\", \"lr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySeX8m7oySYi"
      },
      "outputs": [],
      "source": [
        "def extractor(config):\n",
        "    return config[\"model_path\"], config[\"valid_df\"], config[\"lr\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "me5knQxe-HMi"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def select_model(models, extract, value):\n",
        "    result = None\n",
        "    for _, model in models.items():\n",
        "        config = model[\"config\"]\n",
        "        state = extract(config)\n",
        "        if state == value:\n",
        "            if result is not None:\n",
        "                return None\n",
        "            result = model\n",
        "    return copy.deepcopy(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdHpZl-P1jAy",
        "outputId": "8faf81b9-b595-43cc-8991-32eaaacd78fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating:  ('roberta-large', 'boolq_valid', 0.0002)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.8617737003058104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.8285123966942148\n",
            "Evaluating:  ('roberta-large', 'altboolq_valid_v5', 0.0002)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.8464831804281345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.8292011019283747\n",
            "Evaluating:  ('roberta-large', 'allboolq_valid_v5_half', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.8559633027522936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.8323002754820936\n",
            "Evaluating:  ('roberta-base', 'boolq_valid', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.810091743119266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7830578512396694\n",
            "Evaluating:  ('roberta-base', 'altboolq_valid_v5', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7669724770642202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7620523415977961\n",
            "Evaluating:  ('roberta-base', 'allboolq_valid_v5_half', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7990825688073394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7847796143250688\n",
            "Evaluating:  ('bert-large-cased', 'boolq_valid', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7764525993883792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7524104683195593\n",
            "Evaluating:  ('bert-large-cased', 'altboolq_valid_v5', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7403669724770642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7610192837465565\n",
            "Evaluating:  ('bert-large-cased', 'allboolq_valid_v5_half', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7785932721712538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7716942148760331\n",
            "Evaluating:  ('bert-base-cased', 'boolq_valid', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7431192660550459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.712465564738292\n",
            "Evaluating:  ('bert-base-cased', 'altboolq_valid_v5', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.710091743119266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "altboolq_valid_v5: 0.7238292011019284\n",
            "Evaluating:  ('bert-base-cased', 'allboolq_valid_v5_half', 0.0004)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "boolq_valid: 0.7611620795107034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "pred_dfs = {df_name: dfs[df_name].copy(deep=True) for df_name in df_names}\n",
        "\n",
        "for value in values:\n",
        "    model = select_model(models, extractor, value)\n",
        "    if model is None:\n",
        "        print(\"No model for: \", value)\n",
        "        continue\n",
        "    result = {}\n",
        "    for value_name, v in zip(value_names, value):\n",
        "        result[value_name] = v\n",
        "    print(\"Evaluating: \", value)\n",
        "\n",
        "    for df_name in df_names:\n",
        "        df = dfs[df_name]\n",
        "        preds = predict(df, model[\"path\"], model[\"config\"])\n",
        "        pred_dfs[df_name][values_format.format(*value)] = preds\n",
        "\n",
        "        accuracy = (df[\"label\"] == preds).mean()\n",
        "        result[df_name] = accuracy\n",
        "        print(\"{}: {}\".format(df_name, accuracy))\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqn7J2GHC_lB"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame.from_records(results)\n",
        "\n",
        "weights = np.array([len(dfs[df_name]) for df_name in df_names])\n",
        "weights = weights / np.sum(weights)\n",
        "\n",
        "results_df[\"overall\"] = results_df[df_names].dot(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upzUKBLFEe2K"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ1WgFoT_ZFw"
      },
      "outputs": [],
      "source": [
        "pred_dfs[\"altboolq_valid_v5\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0351009751ab491e83e6e896cbb78b52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d750302d988447cb11ded4da36ed541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34485ae589f34d898fd1535eb2a59dda",
            "placeholder": "",
            "style": "IPY_MODEL_f2a862e21b2c4defb6f638c4bd462768",
            "value": "1359.774 MB of 1359.774 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "108228e49d0943f19e6e0d7c7832d152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6947c5baf8d4d2d80b5f590ecc93495",
            "placeholder": "",
            "style": "IPY_MODEL_cdd3bd833d3449e8974de60ab263f34c",
            "value": "477.841 MB of 477.841 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1277a2af1b314054bb77587439c6ed0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_203c92d14bff4afda086771588bfe3cb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bcfca6c08ff48b9a7e5ca1e627ce34d",
            "value": 1
          }
        },
        "1617a802d24f4cf2b9780c0b5f5cd358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7e7a7f97a384dc5852184cc7be06db6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7083c50ac0ad40b897231c689f649583",
            "value": 1
          }
        },
        "203c92d14bff4afda086771588bfe3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ccbc021a564c20847379fc4b5bfbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34485ae589f34d898fd1535eb2a59dda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fcf84bab344dcea55f5db2b8f4dcbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39c19ccd20a54452afa6bef88184a198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f843dc2dd744a1937cdc2c6206ffab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ccbc021a564c20847379fc4b5bfbfe",
            "value": 1
          }
        },
        "450545f2db7e4433abcdd677c1f03a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_108228e49d0943f19e6e0d7c7832d152",
              "IPY_MODEL_1617a802d24f4cf2b9780c0b5f5cd358"
            ],
            "layout": "IPY_MODEL_e830c57b342f4790a779f1b4a80aa35d"
          }
        },
        "4e6d68e42d214a12bca2c474c6b06b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_532f021641ee4b01984ed9051344735d",
            "placeholder": "",
            "style": "IPY_MODEL_34fcf84bab344dcea55f5db2b8f4dcbf",
            "value": "100%"
          }
        },
        "532f021641ee4b01984ed9051344735d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a433da7572548d8bfcf1d79f5c3d285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7083c50ac0ad40b897231c689f649583": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "741705ca36c34d7aabb7ce438dca1f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0351009751ab491e83e6e896cbb78b52",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a433da7572548d8bfcf1d79f5c3d285",
            "value": 3
          }
        },
        "78524a702c13478c87a19ad63dbeb419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f913019f7f604034a3f16e76d3206290",
              "IPY_MODEL_39c19ccd20a54452afa6bef88184a198"
            ],
            "layout": "IPY_MODEL_bf9e4659b41e41be85de337a5fd4b64c"
          }
        },
        "9bcfca6c08ff48b9a7e5ca1e627ce34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6c48168bea24dc5b73ab4c8eaa401ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9eb488922d641188a63eba6ad60f529": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf9ef56e35540488fc3b1ff176bd42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf9e4659b41e41be85de337a5fd4b64c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd3bd833d3449e8974de60ab263f34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d018ee9ee8f744769e62732178ef4a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e6d68e42d214a12bca2c474c6b06b97",
              "IPY_MODEL_741705ca36c34d7aabb7ce438dca1f4f",
              "IPY_MODEL_fc27ca98d0914522a05ec9a91ed2203d"
            ],
            "layout": "IPY_MODEL_eff36053cbf4492eaf84f7838c4b5c7f"
          }
        },
        "d1f1cbdbbfa342409bd5b818d84b6806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23a90289e9a4e319c4528430f539752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d750302d988447cb11ded4da36ed541",
              "IPY_MODEL_1277a2af1b314054bb77587439c6ed0e"
            ],
            "layout": "IPY_MODEL_b9eb488922d641188a63eba6ad60f529"
          }
        },
        "e4f843dc2dd744a1937cdc2c6206ffab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6947c5baf8d4d2d80b5f590ecc93495": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e7a7f97a384dc5852184cc7be06db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e830c57b342f4790a779f1b4a80aa35d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff36053cbf4492eaf84f7838c4b5c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a862e21b2c4defb6f638c4bd462768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f913019f7f604034a3f16e76d3206290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c48168bea24dc5b73ab4c8eaa401ab",
            "placeholder": "",
            "style": "IPY_MODEL_bdf9ef56e35540488fc3b1ff176bd42b",
            "value": "1359.774 MB of 1359.774 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "f9ecc3760ebf46299a989d0c15c1feb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc27ca98d0914522a05ec9a91ed2203d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ecc3760ebf46299a989d0c15c1feb9",
            "placeholder": "",
            "style": "IPY_MODEL_d1f1cbdbbfa342409bd5b818d84b6806",
            "value": " 3/3 [00:00&lt;00:00, 91.61it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
